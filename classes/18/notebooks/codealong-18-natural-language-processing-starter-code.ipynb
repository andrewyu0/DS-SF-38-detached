{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-38 | 18 | Natural Language Processing | Codelong | Starter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import nltk\n",
    "# nltk.download()\n",
    "\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <<< One-time setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A | Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk import tokenize, corpus, stem\n",
    "\n",
    "from sklearn import feature_extraction, linear_model, ensemble, model_selection, metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(document):\n",
    "    document = document.encode('utf-8')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenize.word_tokenize(document)\n",
    "\n",
    "    # Remove punctuation in tokens and then remove empty tokens\n",
    "    tokens = [token.translate(None, string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if not token in corpus.stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'wait', 'another', 'third']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(\"This is a sentence...  Wait, here's another.  And a third!\")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [Stemmer.stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentenc', 'wait', u'anoth', 'third']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Stemmer.stem_tokens(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B | Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will be analyzing a partial list of the reviews for J.K. Rowling's The Casual Vacancy.  (https://www.amazon.com/dp/0316228532)  We scrapped this dataset during class 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'dataset-18-reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>R3OQUWVA2PRCEA</td>\n",
       "      <td>Jo B.</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Good read</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>R1FJA1XIBRBLES</td>\n",
       "      <td>Cheryl Dulin</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>A great kicker in the beginning AND the end yo...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>R3CFMLYBUJ0295</td>\n",
       "      <td>Eric P Albrecht</td>\n",
       "      <td>A clear triumph of a novel!</td>\n",
       "      <td>A clear triumph of a novel. Have always loved ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>R1FMT3KY928NJB</td>\n",
       "      <td>tlckirk</td>\n",
       "      <td>Disappointing</td>\n",
       "      <td>If it were any other author I would have stopp...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>R138WXOO423PP4</td>\n",
       "      <td>Skelsogeo</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>A great read</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>RT2TE0W92SL67</td>\n",
       "      <td>Tricia K.</td>\n",
       "      <td>Seriously?  $17 bucks for a computer file???  ...</td>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R14ZGYPSP9H0Y7</td>\n",
       "      <td>Pretzel</td>\n",
       "      <td>A must read</td>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R1913ISIDAGQ1A</td>\n",
       "      <td>Prodigy</td>\n",
       "      <td>I love it</td>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R2JY771IW7RI3R</td>\n",
       "      <td>David Katz</td>\n",
       "      <td>Kendle price too expensive</td>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R22B7K1DUJR6ZN</td>\n",
       "      <td>M. A. Barnett</td>\n",
       "      <td>too expensive</td>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5917 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date              id           author  \\\n",
       "0     2017-10-23  R3OQUWVA2PRCEA            Jo B.   \n",
       "1     2017-10-12  R1FJA1XIBRBLES     Cheryl Dulin   \n",
       "2     2017-10-12  R3CFMLYBUJ0295  Eric P Albrecht   \n",
       "3     2017-10-09  R1FMT3KY928NJB          tlckirk   \n",
       "4     2017-10-07  R138WXOO423PP4        Skelsogeo   \n",
       "...          ...             ...              ...   \n",
       "5912  2012-09-27   RT2TE0W92SL67        Tricia K.   \n",
       "5913  2012-09-27  R14ZGYPSP9H0Y7          Pretzel   \n",
       "5914  2012-09-27  R1913ISIDAGQ1A          Prodigy   \n",
       "5915  2012-09-27  R2JY771IW7RI3R       David Katz   \n",
       "5916  2012-09-27  R22B7K1DUJR6ZN    M. A. Barnett   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                            Five Stars   \n",
       "1                                            Four Stars   \n",
       "2                           A clear triumph of a novel!   \n",
       "3                                         Disappointing   \n",
       "4                                            Five Stars   \n",
       "...                                                 ...   \n",
       "5912  Seriously?  $17 bucks for a computer file???  ...   \n",
       "5913                                        A must read   \n",
       "5914                                          I love it   \n",
       "5915                         Kendle price too expensive   \n",
       "5916                                      too expensive   \n",
       "\n",
       "                                                   body  star_rating  \n",
       "0                                             Good read          5.0  \n",
       "1     A great kicker in the beginning AND the end yo...          4.0  \n",
       "2     A clear triumph of a novel. Have always loved ...          4.0  \n",
       "3     If it were any other author I would have stopp...          2.0  \n",
       "4                                          A great read          5.0  \n",
       "...                                                 ...          ...  \n",
       "5912  Premise sounds dull as dirt.  For $17 for a co...          1.0  \n",
       "5913  The depth of character development and storyli...          5.0  \n",
       "5914  The book was great and I will love to re-read ...          5.0  \n",
       "5915  I started to order the kindle edition and than...          5.0  \n",
       "5916  I would love to buy this book but it is too ex...          1.0  \n",
       "\n",
       "[5917 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['date', 'id', 'author', 'title'],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good read</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A great kicker in the beginning AND the end yo...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A clear triumph of a novel. Have always loved ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If it were any other author I would have stopp...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A great read</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  star_rating\n",
       "0                                             Good read          5.0\n",
       "1     A great kicker in the beginning AND the end yo...          4.0\n",
       "2     A clear triumph of a novel. Have always loved ...          4.0\n",
       "3     If it were any other author I would have stopp...          2.0\n",
       "4                                          A great read          5.0\n",
       "...                                                 ...          ...\n",
       "5912  Premise sounds dull as dirt.  For $17 for a co...          1.0\n",
       "5913  The depth of character development and storyli...          5.0\n",
       "5914  The book was great and I will love to re-read ...          5.0\n",
       "5915  I started to order the kindle edition and than...          5.0\n",
       "5916  I would love to buy this book but it is too ex...          1.0\n",
       "\n",
       "[5917 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive, neutral, and negatives reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    1548\n",
       "1.0    1206\n",
       "4.0    1203\n",
       "2.0     983\n",
       "3.0     974\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "#  1, 2 to -1 , 3 to 0, 4,5 to 1\n",
    "df.star_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewyu/anaconda/lib/python2.7/site-packages/pandas/core/generic.py:2999: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# The reason we're doing this is we want the negatives to be negative, and postivies to be postive\n",
    "df.star_rating = df.star_rating.map({1:-1, 2:-1, 3:0, 4:1, 5:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2751\n",
       "-1    2189\n",
       " 0     974\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.star_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.polarity = df.star_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrix and response vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# what is going to be my matrix and response vector\n",
    "X = df.body\n",
    "c = df.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split, added the stratify\n",
    "# stratify is when we have unbalanced classes. eg 90% A, 10% B\n",
    "# Keep the ratio\n",
    "# this order is part of the API\n",
    "train_X, test_X, train_c, test_c = model_selection.train_test_split(X, c, stratify = c, train_size = .6, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF and `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "# What are we doing here? \n",
    "# we are calculating the tfidf matrix - this is awesome!\n",
    "# what does the .fit() do? gives us the maxes and min\n",
    "# here it figures out what all the words are\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = 'english')\n",
    "vectorizer.fit(train_X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00',\n",
       " u'000',\n",
       " u'02',\n",
       " u'04',\n",
       " u'08',\n",
       " u'10',\n",
       " u'100',\n",
       " u'100pages',\n",
       " u'11',\n",
       " u'112',\n",
       " u'12',\n",
       " u'120',\n",
       " u'124',\n",
       " u'125',\n",
       " u'13',\n",
       " u'130',\n",
       " u'132',\n",
       " u'13hrs',\n",
       " u'14',\n",
       " u'142',\n",
       " u'149',\n",
       " u'15',\n",
       " u'150',\n",
       " u'16',\n",
       " u'17',\n",
       " u'170',\n",
       " u'1700',\n",
       " u'175',\n",
       " u'18',\n",
       " u'180',\n",
       " u'1860',\n",
       " u'19',\n",
       " u'194',\n",
       " u'1950',\n",
       " u'1960s',\n",
       " u'1984',\n",
       " u'19th',\n",
       " u'1st',\n",
       " u'20',\n",
       " u'200',\n",
       " u'2000',\n",
       " u'2004',\n",
       " u'2005',\n",
       " u'2007',\n",
       " u'2012',\n",
       " u'2013',\n",
       " u'2014',\n",
       " u'2015',\n",
       " u'2016',\n",
       " u'21',\n",
       " u'21st',\n",
       " u'22',\n",
       " u'23',\n",
       " u'24',\n",
       " u'240',\n",
       " u'25',\n",
       " u'2500',\n",
       " u'26',\n",
       " u'27',\n",
       " u'29',\n",
       " u'2nd',\n",
       " u'2star',\n",
       " u'30',\n",
       " u'300',\n",
       " u'31',\n",
       " u'323',\n",
       " u'35',\n",
       " u'350',\n",
       " u'38',\n",
       " u'380',\n",
       " u'3rd',\n",
       " u'40',\n",
       " u'400',\n",
       " u'44',\n",
       " u'450',\n",
       " u'46',\n",
       " u'50',\n",
       " u'500',\n",
       " u'500th',\n",
       " u'502',\n",
       " u'503',\n",
       " u'505',\n",
       " u'50pages',\n",
       " u'50th',\n",
       " u'512',\n",
       " u'53',\n",
       " u'56',\n",
       " u'5days',\n",
       " u'5th',\n",
       " u'60',\n",
       " u'600',\n",
       " u'60s',\n",
       " u'61',\n",
       " u'620m',\n",
       " u'639',\n",
       " u'64',\n",
       " u'65',\n",
       " u'6th',\n",
       " u'70',\n",
       " u'70s',\n",
       " u'71',\n",
       " u'73',\n",
       " u'75',\n",
       " u'79',\n",
       " u'7th',\n",
       " u'80',\n",
       " u'800',\n",
       " u'81',\n",
       " u'84',\n",
       " u'85',\n",
       " u'89',\n",
       " u'8th',\n",
       " u'90',\n",
       " u'923',\n",
       " u'95',\n",
       " u'98',\n",
       " u'99',\n",
       " u'9th',\n",
       " u'_the',\n",
       " u'aback',\n",
       " u'abandon',\n",
       " u'abandoned',\n",
       " u'abandonment',\n",
       " u'abbey',\n",
       " u'abhorent',\n",
       " u'abide',\n",
       " u'abilities',\n",
       " u'ability',\n",
       " u'abit',\n",
       " u'abject',\n",
       " u'able',\n",
       " u'abortion',\n",
       " u'abound',\n",
       " u'abrupt',\n",
       " u'abruptly',\n",
       " u'absence',\n",
       " u'absolom',\n",
       " u'absolute',\n",
       " u'absolutely',\n",
       " u'absorb',\n",
       " u'absorbed',\n",
       " u'absorbing',\n",
       " u'absorption',\n",
       " u'absurd',\n",
       " u'absurdity',\n",
       " u'abundance',\n",
       " u'abundant',\n",
       " u'abundantly',\n",
       " u'abuse',\n",
       " u'abused',\n",
       " u'abusers',\n",
       " u'abuses',\n",
       " u'abusing',\n",
       " u'abusive',\n",
       " u'abut',\n",
       " u'abutted',\n",
       " u'abutting',\n",
       " u'abysmal',\n",
       " u'accent',\n",
       " u'accents',\n",
       " u'accept',\n",
       " u'acceptable',\n",
       " u'accepted',\n",
       " u'access',\n",
       " u'accesses',\n",
       " u'accident',\n",
       " u'accidental',\n",
       " u'acclaim',\n",
       " u'acclaimed',\n",
       " u'accomodate',\n",
       " u'accompany',\n",
       " u'accomplished',\n",
       " u'accomplishes',\n",
       " u'accomplishment',\n",
       " u'according',\n",
       " u'account',\n",
       " u'accumulation',\n",
       " u'accuracy',\n",
       " u'accurate',\n",
       " u'accurately',\n",
       " u'accurrate',\n",
       " u'accusations',\n",
       " u'accused',\n",
       " u'accustomed',\n",
       " u'ace',\n",
       " u'acerbic',\n",
       " u'ache',\n",
       " u'achieve',\n",
       " u'achieved',\n",
       " u'achievement',\n",
       " u'achievements',\n",
       " u'achievment',\n",
       " u'achingly',\n",
       " u'acknolwedging',\n",
       " u'acknowledge',\n",
       " u'aclaimed',\n",
       " u'acne',\n",
       " u'acohol',\n",
       " u'acorn',\n",
       " u'acquaintances',\n",
       " u'acquainted',\n",
       " u'act',\n",
       " u'acted',\n",
       " u'acting',\n",
       " u'action',\n",
       " u'actions',\n",
       " u'active',\n",
       " u'actively',\n",
       " u'activism',\n",
       " u'activities',\n",
       " u'actor',\n",
       " u'actors',\n",
       " u'actress',\n",
       " u'acts',\n",
       " u'actual',\n",
       " u'actually',\n",
       " u'acute',\n",
       " u'acutely',\n",
       " u'ad',\n",
       " u'adaptation',\n",
       " u'adaptations',\n",
       " u'adapted',\n",
       " u'add',\n",
       " u'added',\n",
       " u'addict',\n",
       " u'addicted',\n",
       " u'addiction',\n",
       " u'addictive',\n",
       " u'addictively',\n",
       " u'addicts',\n",
       " u'adding',\n",
       " u'addition',\n",
       " u'additional',\n",
       " u'address',\n",
       " u'addressed',\n",
       " u'addresses',\n",
       " u'adds',\n",
       " u'adept',\n",
       " u'adeptly',\n",
       " u'adhd',\n",
       " u'adhere',\n",
       " u'adhered',\n",
       " u'adjacent',\n",
       " u'adjectives',\n",
       " u'adjust',\n",
       " u'adjustments',\n",
       " u'adloescents',\n",
       " u'administered',\n",
       " u'admirable',\n",
       " u'admiration',\n",
       " u'admire',\n",
       " u'admired',\n",
       " u'admit',\n",
       " u'admittedly',\n",
       " u'ado',\n",
       " u'adolescence',\n",
       " u'adolescent',\n",
       " u'adolescents',\n",
       " u'adoption',\n",
       " u'adore',\n",
       " u'adored',\n",
       " u'adoring',\n",
       " u'adult',\n",
       " u'adultery',\n",
       " u'adulthood',\n",
       " u'adults',\n",
       " u'aduts',\n",
       " u'advanced',\n",
       " u'advancement',\n",
       " u'advancing',\n",
       " u'advantage',\n",
       " u'adventure',\n",
       " u'adventures',\n",
       " u'adventurous',\n",
       " u'adventurousness',\n",
       " u'adverbs',\n",
       " u'adversity',\n",
       " u'advertised',\n",
       " u'advertisement',\n",
       " u'advertising',\n",
       " u'advertizing',\n",
       " u'advice',\n",
       " u'advise',\n",
       " u'advised',\n",
       " u'advocate',\n",
       " u'advocating',\n",
       " u'affair',\n",
       " u'affairs',\n",
       " u'affect',\n",
       " u'affected',\n",
       " u'affection',\n",
       " u'affects',\n",
       " u'affinity',\n",
       " u'afflicted',\n",
       " u'afflictions',\n",
       " u'affluent',\n",
       " u'afford',\n",
       " u'afforded',\n",
       " u'aforementioned',\n",
       " u'afraid',\n",
       " u'aftermath',\n",
       " u'afternoon',\n",
       " u'afters',\n",
       " u'afterward',\n",
       " u'aga',\n",
       " u'agains',\n",
       " u'agatha',\n",
       " u'age',\n",
       " u'aged',\n",
       " u'ageless',\n",
       " u'agenda',\n",
       " u'agendas',\n",
       " u'agent',\n",
       " u'agents',\n",
       " u'agers',\n",
       " u'ages',\n",
       " u'aggressive',\n",
       " u'aging',\n",
       " u'agitating',\n",
       " u'ago',\n",
       " u'agonist',\n",
       " u'agonizing',\n",
       " u'agony',\n",
       " u'agree',\n",
       " u'agreed',\n",
       " u'agreement',\n",
       " u'ahead',\n",
       " u'aid',\n",
       " u'aim',\n",
       " u'aimed',\n",
       " u'aiming',\n",
       " u'aimlessly',\n",
       " u'aims',\n",
       " u'ain',\n",
       " u'air',\n",
       " u'aired',\n",
       " u'airing',\n",
       " u'airport',\n",
       " u'aisle',\n",
       " u'aka',\n",
       " u'akin',\n",
       " u'al',\n",
       " u'ala',\n",
       " u'alas',\n",
       " u'alastair',\n",
       " u'albeit',\n",
       " u'alcohol',\n",
       " u'alexander',\n",
       " u'alienated',\n",
       " u'aligned',\n",
       " u'alike',\n",
       " u'alittle',\n",
       " u'alive',\n",
       " u'alleged',\n",
       " u'allegiance',\n",
       " u'allegience',\n",
       " u'allegorical',\n",
       " u'allen',\n",
       " u'alley',\n",
       " u'allot',\n",
       " u'alloted',\n",
       " u'allow',\n",
       " u'allowances',\n",
       " u'allowed',\n",
       " u'allowing',\n",
       " u'allows',\n",
       " u'alltogether',\n",
       " u'allusion',\n",
       " u'allusions',\n",
       " u'alot',\n",
       " u'aloud',\n",
       " u'alright',\n",
       " u'alt',\n",
       " u'alter',\n",
       " u'altering',\n",
       " u'alternate',\n",
       " u'alternately',\n",
       " u'alternates',\n",
       " u'alternating',\n",
       " u'alternatively',\n",
       " u'altogether',\n",
       " u'altough',\n",
       " u'amateurish',\n",
       " u'amazed',\n",
       " u'amazement',\n",
       " u'amazes',\n",
       " u'amazing',\n",
       " u'amazingly',\n",
       " u'amazom',\n",
       " u'amazon',\n",
       " u'amazonon',\n",
       " u'ambiguous',\n",
       " u'ambition',\n",
       " u'ambitions',\n",
       " u'ambitious',\n",
       " u'ambivalance',\n",
       " u'ambivalent',\n",
       " u'america',\n",
       " u'american',\n",
       " u'americanized',\n",
       " u'americans',\n",
       " u'amidst',\n",
       " u'amis',\n",
       " u'amounts',\n",
       " u'ample',\n",
       " u'amused',\n",
       " u'amusing',\n",
       " u'amy',\n",
       " u'analogies',\n",
       " u'analysis',\n",
       " u'anatomy',\n",
       " u'ancient',\n",
       " u'anderson',\n",
       " u'andrew',\n",
       " u'ane',\n",
       " u'aneurism',\n",
       " u'aneurysm',\n",
       " u'anew',\n",
       " u'angel',\n",
       " u'angels',\n",
       " u'anger',\n",
       " u'angle',\n",
       " u'angles',\n",
       " u'anglophile',\n",
       " u'anglophiles',\n",
       " u'angry',\n",
       " u'angst',\n",
       " u'animal',\n",
       " u'ann',\n",
       " u'anne',\n",
       " u'annexed',\n",
       " u'anniversary',\n",
       " u'announced',\n",
       " u'announcement',\n",
       " u'annoyed',\n",
       " u'annoying',\n",
       " u'annoyingly',\n",
       " u'anonymous',\n",
       " u'anounced',\n",
       " u'ans',\n",
       " u'answer',\n",
       " u'antagonism',\n",
       " u'antagonist',\n",
       " u'antagonists',\n",
       " u'anthony',\n",
       " u'anti',\n",
       " u'anticipate',\n",
       " u'anticipated',\n",
       " u'anticipating',\n",
       " u'anticipation',\n",
       " u'anticlimactic',\n",
       " u'antics',\n",
       " u'antihero',\n",
       " u'antipathy',\n",
       " u'antipating',\n",
       " u'antithesis',\n",
       " u'antithetic',\n",
       " u'anurysm',\n",
       " u'anxiety',\n",
       " u'anxious',\n",
       " u'anxiously',\n",
       " u'anybody',\n",
       " u'anyday',\n",
       " u'anymore',\n",
       " u'anyones',\n",
       " u'anyways',\n",
       " u'ao',\n",
       " u'apart',\n",
       " u'apathy',\n",
       " u'apex',\n",
       " u'apologies',\n",
       " u'apostrophe',\n",
       " u'appal',\n",
       " u'appalled',\n",
       " u'appalling',\n",
       " u'apparent',\n",
       " u'apparently',\n",
       " u'apparrently',\n",
       " u'appeal',\n",
       " u'appealed',\n",
       " u'appealing',\n",
       " u'appeals',\n",
       " u'appear',\n",
       " u'appearance',\n",
       " u'appearances',\n",
       " u'appeared',\n",
       " u'appearing',\n",
       " u'appears',\n",
       " u'applaud',\n",
       " u'applause',\n",
       " u'apples',\n",
       " u'applied',\n",
       " u'applies',\n",
       " u'apply',\n",
       " u'appreciate',\n",
       " u'appreciated',\n",
       " u'appreciates',\n",
       " u'appreciating',\n",
       " u'appreciation',\n",
       " u'appreciative',\n",
       " u'appreciators',\n",
       " u'apprehensive',\n",
       " u'approach',\n",
       " u'approached',\n",
       " u'approaches',\n",
       " u'appropriate',\n",
       " u'appropriately',\n",
       " u'approve',\n",
       " u'approx',\n",
       " u'approximately',\n",
       " u'apt',\n",
       " u'aquiver',\n",
       " u'arbitrary',\n",
       " u'arc',\n",
       " u'arcadian',\n",
       " u'arch',\n",
       " u'archaic',\n",
       " u'archetypal',\n",
       " u'archives',\n",
       " u'arcs',\n",
       " u'arduous',\n",
       " u'area',\n",
       " u'areas',\n",
       " u'aren',\n",
       " u'arena',\n",
       " u'arf',\n",
       " u'argot',\n",
       " u'argue',\n",
       " u'argued',\n",
       " u'argument',\n",
       " u'arguments',\n",
       " u'arise',\n",
       " u'aristototilian',\n",
       " u'arm',\n",
       " u'arms',\n",
       " u'army',\n",
       " u'aroma',\n",
       " u'arose',\n",
       " u'aroud',\n",
       " u'arranging',\n",
       " u'array',\n",
       " u'arrival',\n",
       " u'arrived',\n",
       " u'arriving',\n",
       " u'arrogance',\n",
       " u'arrogant',\n",
       " u'art',\n",
       " u'artfully',\n",
       " u'artificial',\n",
       " u'artist',\n",
       " u'artistic',\n",
       " u'artistically',\n",
       " u'arundati',\n",
       " u'asan',\n",
       " u'asap',\n",
       " u'ashamed',\n",
       " u'aside',\n",
       " u'ask',\n",
       " u'asked',\n",
       " u'asking',\n",
       " u'asks',\n",
       " u'asleep',\n",
       " u'aspect',\n",
       " u'aspects',\n",
       " u'aspirations',\n",
       " u'aspire',\n",
       " u'assault',\n",
       " u'assemblage',\n",
       " u'assemble',\n",
       " u'assert',\n",
       " u'asserts',\n",
       " u'assessing',\n",
       " u'assessment',\n",
       " u'assign',\n",
       " u'assigned',\n",
       " u'assignment',\n",
       " u'associate',\n",
       " u'associated',\n",
       " u'associating',\n",
       " u'associations',\n",
       " u'assortment',\n",
       " u'assume',\n",
       " u'assumed',\n",
       " u'assuming',\n",
       " u'assumption',\n",
       " u'assumptions',\n",
       " u'assuredly',\n",
       " u'astonish',\n",
       " u'astonished',\n",
       " u'astonishing',\n",
       " u'astonishingly',\n",
       " u'astounding',\n",
       " u'astray',\n",
       " u'astute',\n",
       " u'atlanta',\n",
       " u'atmosphere',\n",
       " u'atonement',\n",
       " u'attach',\n",
       " u'attached',\n",
       " u'attachment',\n",
       " u'attachments',\n",
       " u'attack',\n",
       " u'attacked',\n",
       " u'attempt',\n",
       " u'attempted',\n",
       " u'attempting',\n",
       " u'attempts',\n",
       " u'attendant',\n",
       " u'attended',\n",
       " u'attends',\n",
       " u'attention',\n",
       " u'attitude',\n",
       " u'attitudes',\n",
       " u'attorney',\n",
       " u'attract',\n",
       " u'attracted',\n",
       " u'attributes',\n",
       " u'atypical',\n",
       " u'audible',\n",
       " u'audience',\n",
       " u'audiences',\n",
       " u'audio',\n",
       " u'audiobook',\n",
       " u'audiobooks',\n",
       " u'aunt',\n",
       " u'austen',\n",
       " u'austerity',\n",
       " u'austin',\n",
       " u'australia',\n",
       " u'authentic',\n",
       " u'authenticity',\n",
       " u'author',\n",
       " u'authored',\n",
       " u'authoress',\n",
       " u'authorial',\n",
       " u'authors',\n",
       " u'authuor',\n",
       " u'authur',\n",
       " u'autobiographical',\n",
       " u'automatically',\n",
       " u'av',\n",
       " u'avail',\n",
       " u'available',\n",
       " u'avenues',\n",
       " u'average',\n",
       " u'averaged',\n",
       " u'avid',\n",
       " u'avoid',\n",
       " u'avoided',\n",
       " u'avoiding',\n",
       " u'aw',\n",
       " u'await',\n",
       " u'awaited',\n",
       " u'awaiting',\n",
       " u'awake',\n",
       " u'awakening',\n",
       " u'awakes',\n",
       " u'award',\n",
       " u'aware',\n",
       " u'awareness',\n",
       " u'away',\n",
       " u'awe',\n",
       " u'awed',\n",
       " u'awesome',\n",
       " u'awful',\n",
       " u'awfully',\n",
       " u'awfulness',\n",
       " u'awhile',\n",
       " u'awkward',\n",
       " u'awkwardly',\n",
       " u'ax',\n",
       " u'az',\n",
       " u'babbit',\n",
       " u'baby',\n",
       " u'backbiting',\n",
       " u'backcloth',\n",
       " u'backdoor',\n",
       " u'backdrop',\n",
       " u'background',\n",
       " u'backgrounds',\n",
       " u'backs',\n",
       " u'backstabbing',\n",
       " u'backstories',\n",
       " u'backstory',\n",
       " u'backwards',\n",
       " u'backwater',\n",
       " u'backyard',\n",
       " u'bad',\n",
       " u'baddie',\n",
       " u'badgering',\n",
       " u'badly',\n",
       " u'baffled',\n",
       " u'bag',\n",
       " u'baggage',\n",
       " u'bailed',\n",
       " u'bak',\n",
       " u'balance',\n",
       " u'balanced',\n",
       " u'balances',\n",
       " u'balancing',\n",
       " u'ball',\n",
       " u'balls',\n",
       " u'balm',\n",
       " u'banal',\n",
       " u'banality',\n",
       " u'banana',\n",
       " u'band',\n",
       " u'banging',\n",
       " u'banned',\n",
       " u'bar',\n",
       " u'bard',\n",
       " u'bare',\n",
       " u'barely',\n",
       " u'barrel',\n",
       " u'barry',\n",
       " u'barrymore',\n",
       " u'barrys',\n",
       " u'base',\n",
       " u'based',\n",
       " u'baser',\n",
       " u'basest',\n",
       " u'bashing',\n",
       " u'basic',\n",
       " u'basically',\n",
       " u'basis',\n",
       " u'bask',\n",
       " u'basket',\n",
       " u'bat',\n",
       " u'bated',\n",
       " u'bath',\n",
       " u'bathroom',\n",
       " u'batman',\n",
       " u'battle',\n",
       " u'battles',\n",
       " u'bawl',\n",
       " u'bbc',\n",
       " u'beach',\n",
       " u'bear',\n",
       " u'bearing',\n",
       " u'bears',\n",
       " u'beat',\n",
       " u'beaten',\n",
       " u'beaters',\n",
       " u'beating',\n",
       " u'beats',\n",
       " u'beautiful',\n",
       " u'beautifully',\n",
       " u'beauty',\n",
       " u'bed',\n",
       " u'bedroom',\n",
       " u'bedside',\n",
       " u'bedtime',\n",
       " u'beedle',\n",
       " u'began',\n",
       " u'beget',\n",
       " u'begin',\n",
       " u'beginning',\n",
       " u'begins',\n",
       " u'begun',\n",
       " u'behave',\n",
       " u'behaving',\n",
       " u'behavior',\n",
       " u'behaviors',\n",
       " u'behaviour',\n",
       " u'beingness',\n",
       " u'beings',\n",
       " u'beleive',\n",
       " u'belief',\n",
       " u'beliefs',\n",
       " u'believable',\n",
       " u'believe',\n",
       " u'believeable',\n",
       " u'believed',\n",
       " u'believer',\n",
       " u'believes',\n",
       " u'believing',\n",
       " u'bell',\n",
       " u'bellchapel',\n",
       " u'belligerant',\n",
       " u'belly',\n",
       " u'belong',\n",
       " u'belonged',\n",
       " u'belongs',\n",
       " u'beloved',\n",
       " u'belt',\n",
       " u'bender',\n",
       " u'beneath',\n",
       " u'benefit',\n",
       " u'benefited',\n",
       " u'benefitted',\n",
       " u'bent',\n",
       " u'berate',\n",
       " u'bereavement',\n",
       " u'bereft',\n",
       " u'beset',\n",
       " u'beskrivelser',\n",
       " u'beskriver',\n",
       " u'best',\n",
       " u'besting',\n",
       " u'bestseller',\n",
       " u'bestselling',\n",
       " u'bet',\n",
       " u'betrayal',\n",
       " u'betrayed',\n",
       " u'better',\n",
       " u'bevy',\n",
       " u'beware',\n",
       " u'bewildered',\n",
       " u'beyong',\n",
       " u'bias',\n",
       " u'biased',\n",
       " u'bible',\n",
       " u'bibliophile',\n",
       " u'bickering',\n",
       " u'biddlebaum',\n",
       " u'bifurcated',\n",
       " u'big',\n",
       " u'bigger',\n",
       " u'biggest',\n",
       " u'bigotry',\n",
       " u'bigots',\n",
       " u'bigtime',\n",
       " u'bike',\n",
       " u'billion',\n",
       " u'bin',\n",
       " u'binchey',\n",
       " u'binchy',\n",
       " u'bind',\n",
       " u'binding',\n",
       " u'binging',\n",
       " u'biographical',\n",
       " u'bird',\n",
       " u'birth',\n",
       " u'birthday',\n",
       " u'bit',\n",
       " u'bitching',\n",
       " u'biting',\n",
       " u'bits',\n",
       " u'bitter',\n",
       " u'bitterlky',\n",
       " u'bitterness',\n",
       " u'bittersweet',\n",
       " u'bla',\n",
       " u'black',\n",
       " u'blade',\n",
       " u'blades',\n",
       " u'blah',\n",
       " u'blame',\n",
       " u'blamed',\n",
       " u'blaming',\n",
       " u'blanch',\n",
       " u'bland',\n",
       " u'blank',\n",
       " u'blasphemy',\n",
       " u'blatantly',\n",
       " u'bleach',\n",
       " u'bleak',\n",
       " u'bleaker',\n",
       " u'bleakness',\n",
       " u'bleeding',\n",
       " u'bleh',\n",
       " u'blend',\n",
       " u'blended',\n",
       " u'blending',\n",
       " u'blessed',\n",
       " u'blessings',\n",
       " u'blew',\n",
       " u'blight',\n",
       " u'blind',\n",
       " u'blindness',\n",
       " u'bloated',\n",
       " u'block',\n",
       " u'blockbuster',\n",
       " u'blocks',\n",
       " u'blocky',\n",
       " u'blog',\n",
       " u'blood',\n",
       " u'bloody',\n",
       " u'blooms',\n",
       " u'blotted',\n",
       " u'blow',\n",
       " u'blown',\n",
       " u'blows',\n",
       " u'bludgeons',\n",
       " u'blue',\n",
       " u'bluffed',\n",
       " u'blunt',\n",
       " u'blur',\n",
       " u'blurb',\n",
       " u'blush',\n",
       " u'blyton',\n",
       " u'board',\n",
       " u'boarding',\n",
       " u'boat',\n",
       " u'body',\n",
       " u'bog',\n",
       " u'bogged',\n",
       " u'bohjalian',\n",
       " u'boil',\n",
       " u'boiling',\n",
       " u'boils',\n",
       " u'boks',\n",
       " u'bold',\n",
       " u'boldly',\n",
       " u'boldness',\n",
       " u'bomb',\n",
       " u'bombarded',\n",
       " u'bombs',\n",
       " u'bone',\n",
       " u'bones',\n",
       " u'bonfire',\n",
       " u'bonus',\n",
       " u'boo',\n",
       " u'book',\n",
       " u'bookclub',\n",
       " u'bookmarked',\n",
       " u'books',\n",
       " u'bookshelf',\n",
       " u'bookshelves',\n",
       " u'bookshop',\n",
       " u'bookso',\n",
       " u'bookstore',\n",
       " u'bookstores',\n",
       " u'boomers',\n",
       " u'booming',\n",
       " u'boook',\n",
       " u'boooorrrringggg',\n",
       " u'boor',\n",
       " u'boorish',\n",
       " u'boost',\n",
       " u'boot',\n",
       " u'border',\n",
       " u'bordered',\n",
       " u'borders',\n",
       " u'bore',\n",
       " u'bored',\n",
       " u'boredom',\n",
       " u'boreing',\n",
       " u'boring',\n",
       " u'boringly',\n",
       " u'born',\n",
       " u'borrow',\n",
       " u'borrowed',\n",
       " u'borrowing',\n",
       " u'bother',\n",
       " u'bothered',\n",
       " u'bothering',\n",
       " u'bought',\n",
       " u'bounces',\n",
       " u'bouncing',\n",
       " u'bound',\n",
       " u'bounds',\n",
       " u'boutiques',\n",
       " u'bow',\n",
       " u'box',\n",
       " u'boxes',\n",
       " u'boy',\n",
       " u'boys',\n",
       " u'brain',\n",
       " u'brakes',\n",
       " u'branch',\n",
       " u'branched',\n",
       " u'branching',\n",
       " u'brand',\n",
       " u'brands',\n",
       " u'brava',\n",
       " u'bravado',\n",
       " u'brave',\n",
       " u'bravery',\n",
       " u'bravo',\n",
       " u'brazenly',\n",
       " u'breadth',\n",
       " u'break',\n",
       " u'breakaway',\n",
       " u'breaker',\n",
       " u'breaking',\n",
       " u'breaks',\n",
       " u'breath',\n",
       " u'breathe',\n",
       " u'breathed',\n",
       " u'breather',\n",
       " u'breathes',\n",
       " u'breathtaking',\n",
       " u'breed',\n",
       " u'breeze',\n",
       " u'brew',\n",
       " u'brick',\n",
       " u'bridgewater',\n",
       " u'brief',\n",
       " u'briefly',\n",
       " u'bright',\n",
       " u'brighter',\n",
       " u'brightness',\n",
       " u'brilliance',\n",
       " u'brilliant',\n",
       " u'brilliantly',\n",
       " u'brim',\n",
       " u'bring',\n",
       " u'bringing',\n",
       " u'brings',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed feature matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# here it actually creates the tfidf matrix, thats what transform does\n",
    "# what we do on the train we do on the test\n",
    "train_X = vectorizer.transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do logistic regresison model and/or random forest\n",
    "\n",
    "model = linear_model.LogisticRegression().fit(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81031567080045097"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the train_X cause theres hella 0s\n",
    "train_X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True Class</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypothesized Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1166</td>\n",
       "      <td>192</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142</td>\n",
       "      <td>286</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True Class            -1    0     1\n",
       "Hypothesized Class                 \n",
       "-1                  1166  192    46\n",
       " 0                     5  106     2\n",
       " 1                   142  286  1603"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_hat = model.predict(train_X)\n",
    "\n",
    "pd.crosstab(c_hat,\n",
    "           train_c,\n",
    "            rownames = ['Hypothesized Class'],\n",
    "            colnames = ['True Class']\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
